name: Run Decoder

on:
  push:
    branches: [main, test/streaming-ppi]
  pull_request:
    branches: [main, test/streaming-ppi]
  workflow_dispatch:

jobs:
  run-decoder:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      # Pull prebuilt Docker image from Docker Hub
      - name: Pull prebuilt Docker image
        run: |
          echo "${{ secrets.DOCKER_HUB_ACCESS_TOKEN }}" | docker login -u samribahta --password-stdin
          docker pull samribahta/decoder-image:latest
      - name: Create output directories
        run: |
          mkdir -p ${{ github.workspace }}/plots/cluster
          mkdir -p ${{ github.workspace }}/results
          chmod -R 777 ${{ github.workspace }}/plots
          chmod -R 777 ${{ github.workspace }}/results
      - name: Check available processors and usage percentage
        id: cpu-check
        run: |
          TOTAL_CPUS=$(nproc)
          USED_CPUS=4
          PERCENT_USED=$(( 100 * USED_CPUS / TOTAL_CPUS ))
          echo "Total available processors: $TOTAL_CPUS"
          echo "Processors used for decoder: $USED_CPUS"
          echo "Percent of processors used: ${PERCENT_USED}%"
          echo "total_cpus=$TOTAL_CPUS" >> $GITHUB_OUTPUT
          echo "percent_used=$PERCENT_USED" >> $GITHUB_OUTPUT
      # 2Ô∏è. Download Amazon dataset from GitHub Release
      - name: Fetch amazon0302.pkl from GitHub Release
        run: |
          echo " Downloading amazon0302.pkl from GitHub Releases..."
          wget -O amazon0302.pkl https://github.com/Samrawitgebremaryam/neural-subgraph-matcher-miner/releases/download/v1.0/amazon0302.pkl

          echo " Verifying downloaded file..."
          file amazon0302.pkl

          FILE_SIZE=$(stat -c%s amazon0302.pkl)
          echo "File size: $FILE_SIZE bytes"

          if [ $FILE_SIZE -lt 100000 ]; then
            echo " ERROR: amazon0302.pkl is too small. Likely not downloaded correctly!"
            exit 1
          fi

          if file amazon0302.pkl | grep -Eq "HTML|ASCII|Unicode"; then
            echo " ERROR: amazon0302.pkl is not a valid binary file!"
            exit 1
          fi
          echo " amazon0302.pkl verified as binary."

      #  Run Streaming Mode using prebuilt Docker image
      - name: Run Streaming Mode (Amazon)
        run: |
          docker run --rm \
            -v ${{ github.workspace }}:/app \
            -e PYTHONUNBUFFERED=1 \
            samribahta/decoder-image:latest \
            bash -c "
              set -e
              echo '=== Starting STREAMING (BATCH) MODE Benchmark ==='
              python -m subgraph_mining.decoder \
                --dataset=amazon0302.pkl \
                --model_path=ckpt/model.pt \
                --n_neighborhoods=10000 \
                --n_trials=1000 \
                --min_pattern_size=3 \
                --max_pattern_size=8 \
                --search_strategy=greedy \
                --min_neighborhood_size=20 \
                --max_neighborhood_size=29 \
                --node_anchored \
                --streaming_workers=4 \
                --auto_streaming_threshold=100 \
                --out_path=/app/results/amazon_batch.pkl \
                --visualize_instances
              
              echo '=== Streaming Mode Complete ==='
              ls -la /app/results
            "
      # - name: Run pattern counter in Docker container
      #   run: |
      #     docker run --rm \
      #       -v ${{ github.workspace }}:/app \
      #       -e PYTHONUNBUFFERED=1 \
      #       samribahta/decoder-image:latest \
      #       bash -c "
      #         set -e
      #         export PYTHONPATH=/app
      #         echo 'Running pattern counter...'
      #         python -m analyze.count_patterns \
      #           --dataset=graph.pkl \
      #           --queries_path=results/patterns.pkl \
      #           --out_path=results/ \
      #           --node_anchored \
      #           --preserve_labels
      #         echo 'Counting completed.'
      #         ls -la /app/results
      #       "
      # - name: Run matcher in Docker container
      #   run: |
      #     docker run --rm \
      #       -v ${{ github.workspace }}:/app \
      #       -e PYTHONUNBUFFERED=1 \
      #       samribahta/decoder-image:latest \
      #       bash -c "
      #         set -e
      #         echo 'Starting matcher run on custom gene graph...'
      #         python -m subgraph_matching.train \
      #           --dataset=graph \
      #           --graph_pkl_path=graph.pkl \
      #           --node_anchored \
      #           --batch_size 16 \
      #           --val_size 128
      #         echo 'Checking output directories...'
      #         ls -la /app/results
      #         ls -la /app/plots
      #       "

      - name: Check for generated files
        run: |
          echo "Checking plots directory:"
          ls -R plots/ || echo "No plots directory found"
          echo "Checking results directory:"
          ls -R results/ || echo "No results directory found"
      - name: Upload plots as artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: decoder-plots
          path: |
            plots/
            results/
          retention-days: 7
          if-no-files-found: warn

      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: decoder-logs
          path: |
            *.log
            *.err
          if-no-files-found: ignore
