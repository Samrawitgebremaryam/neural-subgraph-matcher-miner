name: Run Decoder

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:

jobs:
  run-decoder:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2

      - name: Cache Docker layers
        uses: actions/cache@v3
        with:
          path: /tmp/.buildx-cache
          key: ${{ runner.os }}-buildx-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-buildx-

      - name: Build Docker image
        uses: docker/build-push-action@v4
        with:
          context: .
          load: true
          tags: decoder-image:latest
          cache-from: |
            type=local,src=/tmp/.buildx-cache
          cache-to: |
            type=local,dest=/tmp/.buildx-cache-new,mode=max

      - name: Move cache
        run: |
          rm -rf /tmp/.buildx-cache
          mv /tmp/.buildx-cache-new /tmp/.buildx-cache

      - name: Create output directories
        run: |
          mkdir -p ${{ github.workspace }}/plots/cluster
          mkdir -p ${{ github.workspace }}/results
          chmod -R 777 ${{ github.workspace }}/plots
          chmod -R 777 ${{ github.workspace }}/results

      - name: Run Standard Mode (Benchmark)
        run: |
          docker run --rm \
            -v ${{ github.workspace }}:/app \
            -e PYTHONUNBUFFERED=1 \
            decoder-image:latest \
            bash -c "
              echo '=== STANDARD MODE ==='
              python -m subgraph_mining.decoder \
                --dataset=undirected.pkl \
                --n_neighborhoods=1000 \
                --n_trials=100 \
                --min_pattern_size=3 \
                --max_pattern_size=5 \
                --node_anchored \
                --streaming_workers=1 \
                --auto_streaming_threshold=1000000 \
                --out_path=/app/results/patterns_standard.pkl
            " | tee standard_mode.log

      # - name: Run Batch Mode (Benchmark)
      #   run: |
      #     docker run --rm \
      #       -v ${{ github.workspace }}:/app \
      #       -e PYTHONUNBUFFERED=1 \
      #       decoder-image:latest \
      #       bash -c "
      #         echo '=== BATCH MODE ==='
      #         python -m subgraph_mining.decoder \
      #           --dataset=undirected.pkl \
      #           --n_neighborhoods=1000 \
      #           --n_trials=100 \
      #           --min_pattern_size=3 \
      #           --max_pattern_size=5 \
      #           --node_anchored \
      #           --streaming_workers=4 \
      #           --auto_streaming_threshold=100 \
      #           --out_path=/app/results/patterns_batch.pkl
      #       " | tee batch_mode.log

      - name: Compare Results (Parity Check)
        run: |
          python3 -c "
          import pickle, os
          try:
              ps = 'results/patterns_standard.pkl'
              pb = 'results/patterns_batch.pkl'
              if os.path.exists(ps) and os.path.exists(pb):
                  with open(ps, 'rb') as f: s = pickle.load(f)
                  with open(pb, 'rb') as f: b = pickle.load(f)
                  print(f'Standard found {len(s)} patterns')
                  print(f'Batch found {len(b)} patterns')
                  if len(s) == len(b):
                      print('✅ Result Parity Verified!')
                  else:
                      print('⚠ Results differ slightly (normal due to sampling)')
              else:
                  print('Error: Result files missing')
          except Exception as e:
              print(f'Error comparing: {e}')
          "

      - name: Check for generated files
        run: |
          echo "Checking results directory:"
          ls -R results/
      
      - name: Upload Results and Plots
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: |
            plots/
            results/
            *.log
          retention-days: 7